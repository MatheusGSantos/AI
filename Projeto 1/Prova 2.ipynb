{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implementação de Métodos de Machine Learning\n",
    "**Aluno:** Matheus Gama dos Santos - 20180163117<br>\n",
    "**Curso:** Ciência da Computação - UFPB<br>\n",
    "**Profª:** Thais Gaudencio do Rego<br><br>\n",
    "Este projeto consiste na implementação de métodos de Machine Learning para analisar as bases de dados listadas abaixo:\n",
    "- [Titanic: Machine Learning from Disaster](https://www.kaggle.com/c/titanic/data)\n",
    "- [\n",
    "House Prices: Advanced Regression Techniques](https://www.kaggle.com/c/house-prices-advanced-regression-techniques/data)\n",
    "- [2018-2019 Premier League Data\n",
    "](https://www.kaggle.com/thesiff/premierleague1819)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cada base de dados será tratada em uma das 3 seções: **Classificação**, **Regressão** e **Clusterização** (nessa ordem).<br>\n",
    "\n",
    "## Classificação"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#install imblearn\n",
    "!pip install imblearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import modules\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import *\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from imblearn.metrics import sensitivity_score, specificity_score\n",
    "from string import ascii_letters\n",
    "import ipywidgets as widgets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load dataframe\n",
    "titanic_filename = 'titanic/train.csv'\n",
    "titanic_dataframe = pd.read_csv(titanic_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic_dataframe.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select useful attributes\n",
    "titanic_dataframe = titanic_dataframe.drop([\"PassengerId\", \"Name\", \"Ticket\", \"Cabin\", \"Embarked\", \"Fare\"], axis=1)\n",
    "titanic_dataframe.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# converting \"Sex\" attribute\n",
    "titanic_dataframe.Sex = titanic_dataframe.Sex.replace({'male':0, 'female':1})\n",
    "titanic_dataframe.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic_dataframe.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=\"3\">&emsp;&emsp;Analisando o estado atual do *Dataframe*, observa-se que o atributo *Age* possui mais de 100 linhas sem dado. Vamos realizar testes para verificar a influência das linhas com dado faltando.</font><br><br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_titanic_survivability(d_frame_surv): # d_frame_surv: dataframe Survived column\n",
    "    zeros = 0\n",
    "    ones = 0\n",
    "    for numbers in d_frame_surv:\n",
    "        if numbers:\n",
    "            ones += 1\n",
    "        else:\n",
    "            zeros += 1\n",
    "    print(f\"Died: {zeros} ({zeros/(zeros+ones)}), Survived: {ones} ({ones/(zeros+ones)})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Compare dataframe with and without missing data rows\n",
    "\n",
    "# m_df will be titanic_dataframe.Survived without missing values\n",
    "m_df = titanic_dataframe.dropna(axis=0)\n",
    "m_df = np.array(m_df.Survived)\n",
    "\n",
    "# dtf will be a copy of titanic_dataframe.Survived\n",
    "df = np.array(titanic_dataframe.Survived)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare results\n",
    "print('Without missing values:')\n",
    "get_titanic_survivability(m_df)\n",
    "print('\\nWith missing values:')\n",
    "get_titanic_survivability(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=\"3\">&emsp;&emsp;É possível observar que o balanceamento da base de dados, com relação ao *target* ( *Survived* ), não teve alteração significativa ao eliminar os objetos sem o valor do atributo *Age*. Vamos comparar, por fim, o impacto da mudança nos outros atributos.</font><br><br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# description of titanic_dataframe\n",
    "titanic_dataframe.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# description of titanic_dataframe without the missing values\n",
    "titanic_dataframe.dropna(axis=0).describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=\"3\">&emsp;&emsp;O impacto não se mostrou significativo na distribuição dos outros atributos. Agora, vamos normalizar os dados e exibir a matriz de correlação dos atributos relevantes.</font><br><br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic_dataframe = titanic_dataframe.dropna(axis=0)\n",
    "\n",
    "# Normalizing dataframe\n",
    "def normalize_df(df):\n",
    "    d_values = df.values\n",
    "    min_max_scaler = preprocessing.MinMaxScaler()\n",
    "    d_values_scaled = min_max_scaler.fit_transform(d_values)\n",
    "    df_norm = pd.DataFrame(d_values_scaled, columns=df.columns)\n",
    "    return df_norm\n",
    "\n",
    "titanic_dataframe_norm = normalize_df(titanic_dataframe)\n",
    "titanic_dataframe_norm.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correlation Matrix\n",
    "sns.heatmap(titanic_dataframe_norm.corr(), annot=True, fmt=\".2f\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=\"3\">&emsp;&emsp;Em relação ao *target* (*Survived* ), é possível perceber que as correlações mais importantes são entre a classe do indivíduo ( -0,36 ) e o sexo ( 0,54 ). Quanto menor a classe social, mais chance de sobreviver. Também pode-se dizer que o sexo feminino tem mais chance de sobreviver do que o masculino. As outras correlações não apresentam valores expressivos. Analisaremos agora a presença de outliers em cada atributo.</font><br><br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic_dataframe.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=\"3\">&emsp;&emsp;*Survived* é um atributo binário, que também é o target, portanto seus valores tem significado classificatório. Logo, survived não possui outliers. Pclass também possui valores com significado classificatório (1, 2 ou 3), logo não possui outliers. Sex é binário e também possui significado classificatório, logo não possui outliers. Age, aparentemente possui outliers, dado que sua média tem valor aproximado de 29,6991, com desvio padrão de aproximadamente 14,5264. Se considerarmos ( $média + (2dp)$ ), valores acima de 58,7519 podem ser considerados outliers. Porém, nesse caso, a base de dados possui valores entre 58,7519 e 80, que são valores representativos pra base de dados. Além do mais, talvez se utilizássemos ( $média + (3dp)$ ) não consideraríamos como outlier. O mesmo acontece com SibSp e Parch. Para verificar as afirmações, vamos observar os gráficos de cada atributo.</font><br><br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "attribute = 'Survived'\n",
    "def on_change(change):\n",
    "    global attribute\n",
    "    if change['type'] == 'change' and change['name'] == 'value':\n",
    "        attribute = change['new']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w = widgets.Dropdown(\n",
    "    options=[e for e in titanic_dataframe.columns],\n",
    "    value=titanic_dataframe.columns[0],\n",
    "    description='Attribute:',\n",
    "    disabled=False,\n",
    ")\n",
    "\n",
    "w.observe(on_change)\n",
    "\n",
    "display(w)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Obs.: Selecione o atributo e execute as duas próximas células para exibir o histograma e boxplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot histogram\n",
    "titanic_dataframe[attribute].plot(kind='hist',title=attribute ,bins=50,figsize=(8,4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Boxplot\n",
    "titanic_dataframe[attribute].plot(kind='box',figsize=(8,4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=\"3\">&emsp;&emsp;Ao observar os gráficos, vemos que SibSp e Parch são os atributos com verdadeiros outliers e não balanceados por essa mesma razão. Vamos retirar então os valores acima de ( $média + ( 3dp )$ ) dos dois atributos.</font><br><br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropping outliers\n",
    "indexNames = titanic_dataframe[ (titanic_dataframe['SibSp'] > 3) | (titanic_dataframe['Parch'] > 3) ].index\n",
    "titanic_dataframe.drop(indexNames , inplace=True)\n",
    "\n",
    "# get normalized version\n",
    "titanic_dataframe_norm = normalize_df(titanic_dataframe)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=\"3\">Agora temos os dados balanceados e normalizados, prontos para aplicar os modelos.</font><br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select features and target\n",
    "y = titanic_dataframe_norm.Survived\n",
    "x = titanic_dataframe_norm.drop(columns='Survived').to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split train and test\n",
    "train_X, test_X, train_Y, test_Y = model_selection.train_test_split( x, y, random_state=0, test_size=.2 )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=\"3\">&emsp;&emsp;Os modelos escolhidos foram Random Forest e SVM, com a razão da escolha de cada um descrita junto com os resultados após a execução.</font><br><br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random Forest\n",
    "rdf = ensemble.RandomForestClassifier(n_estimators=100, max_depth=3, random_state=2) #max_depth = 3, random_state=2\n",
    "rdf.fit(train_X, train_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_Y = rdf.predict(test_X)\n",
    "def show_metrics(test, pred):\n",
    "    # accuracy: the fraction of predictions the model got right.\n",
    "    accuracy = metrics.accuracy_score(test,pred)\n",
    "\n",
    "    # sensitivy (recall): Percentage of correct predictions out of all the positive classes. (TP / TP+FN).\n",
    "    sensitivity = sensitivity_score(test,pred)\n",
    "    \n",
    "    # specificity: proportion of actual negatives that are correctly identified as such. (TN / FP + TN).\n",
    "    specificity = specificity_score(test,pred)\n",
    "    \n",
    "    \"\"\">Precision (used to calculate f1 score): Out of all the positive classes predicted correctly, how many are actually positive. (TP / TP+FP)\"\"\"\n",
    "    # f1 score (harmonic mean of precision and recall): an accuracy coefficient with values between 0 and 1 (0 and 1 included).\n",
    "    f1_score = metrics.f1_score(test, pred)\n",
    "\n",
    "    x = np.array([accuracy, f1_score, sensitivity, specificity]).reshape(1,4)\n",
    "    return pd.DataFrame(x, columns=[\"Accuracy\", \"F1 Score\",\"Sensitivity\", \"Specificity\"], index=[\"Results\"])\n",
    "\n",
    "results_r_forest = show_metrics(test_Y, pred_Y)\n",
    "results_r_forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# confusion matrix\n",
    "def show_confusion_mat(test,pred):\n",
    "    c_mat = metrics.confusion_matrix(test, pred)\n",
    "    return pd.DataFrame(c_mat, columns=[\"P\", \"N\"], index=[\"P\", \"N\"])\n",
    "mat_r_forest = show_confusion_mat(test_Y,pred_Y)\n",
    "mat_r_forest\n",
    "\n",
    "# TP  FP\n",
    "# FN  TN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=\"3\">&emsp;&emsp;Random Forest é um algoritmo de classificação e regressão, baseado em árvores de decisão, porém seu funcionamento corrige o hábito de realizar *overfitting* sobre a base de treinamento. Com acurácia de 0,861314 e F1-Score de 0,828829, o modelo se mostrou bem eficiente. Utilizando *max_depth* = 3, *random_state* = 2, obteve-se sensibilidade de 0,793103 e especificidade de 0,911392, que podem ser considerados bons resultados. Os valores para os parâmetros utilizados foram obtidos através de testes manuais e comparação.</font><br><br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SVC (SVM)\n",
    "SVC = svm.SVC(gamma=11)\n",
    "SVC.fit(train_X, train_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_Y = SVC.predict(test_X)\n",
    "results_SVC = show_metrics(test_Y, pred_Y)\n",
    "results_SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mat_SVC = show_confusion_mat(test_Y,pred_Y)\n",
    "mat_SVC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=\"3\">&emsp;&emsp;SVM é classificador linear binário não probabilístico que tenta definir uma reta que melhor separa as classes do problema. O fato da razão entre as saídas ser próximo de 1 e os objetos da base só possuírem apenas duas classificações possíveis são a justificativa para a escolha desse algoritmo. Os resultados foram bem satisfatórios, com acurácia de 0,854015 e F1-Score de 0,821429. Os números de acertos positivos e negativos também encontrou altas taxas, com sensibilidade de 0,793103 e especificidade de 0,898734. Foram testados alguns valores para o parâmetro *gamma*, que foi o mais impactante nos resultados quando alterado, dentro do intervalo de 1 a 15, com melhor valor sendo *gamma* = 11. A mudança do gamma para outros valores ocasiona em troca de acurácia e especificidade por sensibilidade, ou apenas a perda em algum dos valores. O estado atual mantém sensibilidade e especificidade balanceados, diminuindo a chance de *overfitting*.</font><br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load dataframes\n",
    "hp_filename = 'house_prices/train.csv'\n",
    "hp_dataframe = pd.read_csv(hp_filename, na_values=None,keep_default_na=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hp_dataframe.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# converting non-numerical attributes\n",
    "file = open('house_prices/dict.txt','r')\n",
    "replaces = file.read()\n",
    "replaces = replaces.split(\";\")\n",
    "for each_element in replaces:\n",
    "    attribute = each_element[2:each_element.find(\"'\",2)]\n",
    "    dictionary = each_element[each_element.find(\"{\",2) +1: each_element.find(\"}\")].split(', ')\n",
    "    dict_rep = {}\n",
    "    for each_n_element in dictionary:\n",
    "        value = each_n_element[each_n_element.find(\": \")+2:]\n",
    "        dict_rep[each_n_element[1:each_n_element.find(\"'\",2)]] = int(value)\n",
    "    hp_dataframe[attribute].replace(dict_rep, inplace=True)\n",
    "file.close()\n",
    "hp_dataframe[hp_dataframe.select_dtypes(\"object\").columns] = hp_dataframe[hp_dataframe.select_dtypes(\"object\").columns].astype('int', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalizing dataframe\n",
    "hp_dataframe = normalize_df(hp_dataframe)\n",
    "hp_dataframe.drop(columns=['Id'], inplace=True)\n",
    "hp_dataframe.sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select features and target\n",
    "y = hp_dataframe.SalePrice\n",
    "x = hp_dataframe.drop(columns='SalePrice').to_numpy()\n",
    "# split train and test\n",
    "train_X, test_X, train_Y, test_Y = model_selection.train_test_split( x, y, random_state=0, test_size=.2 )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=\"3\">&emsp;&emsp;Os modelos escolhidos foram *Linear Regression* e *Random Forest Regression*. *Linear Regression* foi escolhido com o pensamento de que cada um dos atributos é indepente entre si, mas compõem a saída em conjunto. O motivo da escolha do *Random Forest* foi baseada na ideia de que *Decision Trees* tentam tomar decisões seguindo caminhos que melhor representem a situação, sendo a ideia parecida com o problema adotado (classificar o preço de uma casa baseado no preço de outras). *Random Forest* usa várias árvores de decisão e escolher a que melhor representa a ocasião, também com a vantagem de corrigir o hábito de *overfitting*, como já citado.</font><br><br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Linear Regression\n",
    "lr = linear_model.LinearRegression().fit(train_X,train_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_pred = lr.predict(test_X)\n",
    "# Erro Médio Absoluto\n",
    "metrics.mean_absolute_error(lr_pred,test_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Erro Quadrático Médio\n",
    "metrics.mean_squared_error(lr_pred,test_Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=\"3\">&emsp;&emsp;Comment</font><br><br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random Forest\n",
    "rf_reg = ensemble.RandomForestRegressor(n_estimators=400, max_depth=25, random_state=1).fit(train_X,train_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_pred = rf_reg.predict(test_X)\n",
    "# Erro Médio Absoluto\n",
    "metrics.mean_absolute_error(rf_pred,test_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics.mean_squared_error(rf_pred,test_Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=\"3\">&emsp;&emsp;Comment</font><br><br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
